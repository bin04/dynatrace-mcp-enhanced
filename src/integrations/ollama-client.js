import axios from 'axios';

export class OllamaClient {
  constructor(config = {}) {
    this.config = {
      baseUrl: config.baseUrl || 'http://localhost:11434',
      model: config.model || 'llama2',
      timeout: config.timeout || 120000, // Increased to 2 minutes
      maxRetries: config.maxRetries || 3,
      ...config
    };
    
    this.isAvailable = false;
    this.lastHealthCheck = null;
    this.healthCheckInterval = 60000; // 1 minute
  }

  async checkHealth() {
    try {
      const response = await axios.get(`${this.config.baseUrl}/api/tags`, {
        timeout: 5000
      });
      
      this.isAvailable = response.status === 200;
      this.lastHealthCheck = new Date();
      
      if (this.isAvailable) {
        console.log('ü¶ô Ollama service is available');
        // Check if our model is available
        const models = response.data.models || [];
        const hasModel = models.some(m => m.name.includes(this.config.model));
        if (!hasModel) {
          console.log(`‚ö†Ô∏è Model ${this.config.model} not found in Ollama`);
        }
      }
      
      return this.isAvailable;
    } catch (error) {
      this.isAvailable = false;
      this.lastHealthCheck = new Date();
      console.log('‚ùå Ollama service unavailable:', error.message);
      return false;
    }
  }

  async shouldCheckHealth() {
    if (!this.lastHealthCheck) return true;
    const timeSinceCheck = new Date() - this.lastHealthCheck;
    return timeSinceCheck > this.healthCheckInterval;
  }

  async chat(message, context = null) {
    // Check health if needed
    if (await this.shouldCheckHealth()) {
      await this.checkHealth();
    }

    if (!this.isAvailable) {
      throw new Error('Ollama service is not available');
    }

    try {
      const payload = {
        model: this.config.model,
        prompt: this.buildPrompt(message, context),
        stream: false,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          top_k: 40,
          // Add performance options for Phi
          num_ctx: 2048,     // Context window
          num_predict: 512   // Max tokens to generate
        }
      };

      console.log(`ü¶ô Ollama query (${this.config.model}): ${message.substring(0, 100)}...`);
      console.log(`‚è±Ô∏è Timeout set to: ${this.config.timeout}ms`);
      
      const startTime = Date.now();
      const response = await axios.post(
        `${this.config.baseUrl}/api/generate`,
        payload,
        {
          timeout: this.config.timeout,
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );

      const processingTime = Date.now() - startTime;
      
      if (response.data && response.data.response) {
        console.log(`‚úÖ Ollama response received in ${processingTime}ms`);
        return this.formatResponse(response.data.response, processingTime);
      } else {
        throw new Error('Invalid response from Ollama');
      }

    } catch (error) {
      console.error('‚ùå Ollama chat error:', error.message);
      
      if (error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND') {
        this.isAvailable = false;
        throw new Error('Ollama service connection failed');
      }
      
      if (error.response?.status === 404) {
        throw new Error(`Model ${this.config.model} not found in Ollama`);
      }
      
      throw error;
    }
  }

  buildPrompt(message, context = null) {
    let prompt = '';

    // Add context if available
    if (context) {
      prompt += `Context: You are assisting with technical questions about software architecture, observability, and system design.\n\n`;
      
      if (context.currentTopic) {
        prompt += `Current topic: ${context.currentTopic}\n`;
      }
      
      prompt += '\n';
    }

    // Add the user's message
    prompt += `Question: ${message}\n\n`;
    
    // Add guidance for the response
    prompt += `Please provide a concise, helpful technical response. Focus on practical information and avoid overly verbose explanations.`;

    return prompt;
  }

  formatResponse(response, processingTime) {
    // Clean up the response
    let formatted = response.trim();
    
    // Add some context indicators
    formatted += `\n\nüí° *Generated by ${this.config.model} in ${processingTime}ms*`;
    
    return {
      message: formatted,
      source: 'ollama',
      model: this.config.model,
      processingTime: processingTime,
      timestamp: new Date().toISOString()
    };
  }

  async getAvailableModels() {
    try {
      const response = await axios.get(`${this.config.baseUrl}/api/tags`);
      return response.data.models || [];
    } catch (error) {
      console.error('Failed to get Ollama models:', error);
      return [];
    }
  }

  async pullModel(modelName) {
    try {
      console.log(`ü¶ô Pulling model: ${modelName}`);
      const response = await axios.post(
        `${this.config.baseUrl}/api/pull`,
        { name: modelName },
        { timeout: 300000 } // 5 minutes for model pulling
      );
      
      console.log(`‚úÖ Model ${modelName} pulled successfully`);
      return true;
    } catch (error) {
      console.error(`‚ùå Failed to pull model ${modelName}:`, error);
      return false;
    }
  }

  getStatus() {
    return {
      isAvailable: this.isAvailable,
      lastHealthCheck: this.lastHealthCheck,
      config: {
        baseUrl: this.config.baseUrl,
        model: this.config.model,
        timeout: this.config.timeout
      }
    };
  }
}
