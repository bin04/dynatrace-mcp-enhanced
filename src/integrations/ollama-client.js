import axios from 'axios';

export class OllamaClient {
  constructor(config = {}) {
    this.config = {
      baseUrl: config.baseUrl || 'http://localhost:11434',
      model: config.model || 'llama2',
      timeout: config.timeout || 30000,
      maxRetries: config.maxRetries || 3,
      ...config
    };
    
    this.isAvailable = false;
    this.lastHealthCheck = null;
    this.healthCheckInterval = 60000; // 1 minute
  }

  async checkHealth() {
    try {
      const response = await axios.get(`${this.config.baseUrl}/api/tags`, {
        timeout: 5000
      });
      
      this.isAvailable = response.status === 200;
      this.lastHealthCheck = new Date();
      
      if (this.isAvailable) {
        console.log('ü¶ô Ollama service is available');
        // Check if our model is available
        const models = response.data.models || [];
        const hasModel = models.some(m => m.name.includes(this.config.model));
        if (!hasModel) {
          console.log(`‚ö†Ô∏è Model ${this.config.model} not found in Ollama`);
        }
      }
      
      return this.isAvailable;
    } catch (error) {
      this.isAvailable = false;
      this.lastHealthCheck = new Date();
      console.log('‚ùå Ollama service unavailable:', error.message);
      return false;
    }
  }

  async shouldCheckHealth() {
    if (!this.lastHealthCheck) return true;
    const timeSinceCheck = new Date() - this.lastHealthCheck;
    return timeSinceCheck > this.healthCheckInterval;
  }

  async chat(message, context = null) {
    // Check health if needed
    if (await this.shouldCheckHealth()) {
      await this.checkHealth();
    }

    if (!this.isAvailable) {
      throw new Error('Ollama service is not available');
    }

    try {
      const payload = {
        model: this.config.model,
        prompt: this.buildPrompt(message, context),
        stream: false,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          top_k: 40
        }
      };

      console.log(`ü¶ô Ollama query: ${message.substring(0, 100)}...`);
      
      const response = await axios.post(
        `${this.config.baseUrl}/api/generate`,
        payload,
        {
          timeout: this.config.timeout,
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );

      if (response.data && response.data.response) {
        console.log('‚úÖ Ollama response received');
        return this.formatResponse(response.data.response);
      } else {
        throw new Error('Invalid response from Ollama');
      }

    } catch (error) {
      console.error('‚ùå Ollama chat error:', error.message);
      
      if (error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND') {
        this.isAvailable = false;
        throw new Error('Ollama service connection failed');
      }
      
      if (error.response?.status === 404) {
        throw new Error(`Model ${this.config.model} not found in Ollama`);
      }
      
      throw error;
    }
  }

  buildPrompt(message, context = null) {
    let prompt = '';

    // Add context if available
    if (context) {
      prompt += `Context: You are assisting with Dynatrace observability and ADT enterprise systems troubleshooting.\n\n`;
      
      if (context.currentTopic) {
        prompt += `Current topic: ${context.currentTopic}\n`;
      }
      
      if (context.adtContext) {
        prompt += `ADT systems involved: ${context.adtContext.systems?.join(', ') || 'none'}\n`;
        prompt += `Urgency level: ${context.adtContext.urgency || 'normal'}\n`;
      }
      
      prompt += '\n';
    }

    // Add the user's message
    prompt += `Question: ${message}\n\n`;
    
    // Add guidance for the response
    prompt += `Please provide a helpful, technical response focused on observability, troubleshooting, or system architecture. If the question is about ADT systems (OMS, MyADT, MobileTech, etc.), provide specific technical guidance.`;

    return prompt;
  }

  formatResponse(response) {
    // Clean up the response
    let formatted = response.trim();
    
    // Add some context indicators
    if (formatted.length > 500) {
      formatted += '\n\nüí° *This response was generated by Ollama local LLM*';
    }
    
    return {
      message: formatted,
      source: 'ollama',
      model: this.config.model,
      timestamp: new Date().toISOString()
    };
  }

  async getAvailableModels() {
    try {
      const response = await axios.get(`${this.config.baseUrl}/api/tags`);
      return response.data.models || [];
    } catch (error) {
      console.error('Failed to get Ollama models:', error);
      return [];
    }
  }

  async pullModel(modelName) {
    try {
      console.log(`ü¶ô Pulling model: ${modelName}`);
      const response = await axios.post(
        `${this.config.baseUrl}/api/pull`,
        { name: modelName },
        { timeout: 300000 } // 5 minutes for model pulling
      );
      
      console.log(`‚úÖ Model ${modelName} pulled successfully`);
      return true;
    } catch (error) {
      console.error(`‚ùå Failed to pull model ${modelName}:`, error);
      return false;
    }
  }

  getStatus() {
    return {
      isAvailable: this.isAvailable,
      lastHealthCheck: this.lastHealthCheck,
      config: {
        baseUrl: this.config.baseUrl,
        model: this.config.model,
        timeout: this.config.timeout
      }
    };
  }
}
